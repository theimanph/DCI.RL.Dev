{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pyodbc\n",
    "%pip install usaddress\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import usaddress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['DW_SERVER'] = \"pdsqlirisdw01.hosted.lac.com\"\n",
    "os.environ['DW_DB'] = \"PRD_APHIM_UODS_DW\"\n",
    "os.environ['DW_USER'] = \"zz_dssteam\"\n",
    "os.environ['DW_PASS'] = \"$3rv1se0neF1ve\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_addr(df, address_var, apt_var, city_var, state_var, zip_var):\n",
    "    # Replace backslashes with forward slashes in address\n",
    "    df[address_var] = df[address_var].str.replace(r\"\\\\\", \"/\", regex=True)\n",
    "\n",
    "    # Extract fractions like '1/2' or '3/4' from the address\n",
    "    df['addr_frac'] = df[address_var].str.extract(r\"(1/2|3/4)\", expand=False)\n",
    "    df[address_var] = df[address_var].str.replace(r\"1/2|3/4\", \"\", regex=True).str.strip()\n",
    "\n",
    "    # Remove unnecessary punctuation and convert to uppercase\n",
    "    df[address_var] = df[address_var].str.replace(r\"[^a-zA-Z0-9\\s,]\", \" \", regex=True).str.upper().str.strip()\n",
    "    df[apt_var] = df[apt_var].str.replace(r\"[^a-zA-Z0-9\\s#\\-/]\", \" \", regex=True).str.upper().str.strip()\n",
    "\n",
    "    # Remove entirely blank entries\n",
    "    for var in [address_var, apt_var, city_var, state_var, zip_var]:\n",
    "        df[var] = df[var].replace(r\"^\\s*$\", \"\", regex=True)\n",
    "\n",
    "    # Simple regex to extract street (assuming 'number streetname' format)\n",
    "    street_regex = r\"^\\d+\\s[\\w\\s]+\"\n",
    "    df['addr'] = df[address_var].apply(lambda x: re.match(street_regex, x).group() if re.match(street_regex, x) else '')\n",
    "\n",
    "    # Assuming city, state, and zip are already separated correctly\n",
    "    df['city'] = df[city_var]\n",
    "    df['state'] = df[state_var]\n",
    "    df['zip'] = df[zip_var]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the keyword lists\n",
    "invalid_addr1 = \"|\".join([\"UNKNO\", \"HOMELES\", \"NEED ADDR\", \"NEED INFO\", \"HOMESLESS\", \"TRANSIENT\", \"SUPPRESS\", \"ENCAMPM\", \n",
    "                          \"UNDOMIC\", \"UNDERPASS\", \"HOMELESS\", \"NOADDRESS\", \"NO ADDRESS\", \"NONE PROVIDED\", \"REFUSED\", \n",
    "                          \"123 DEFAULT ST\", \"PT STATES NONE\", \"999 TRANSIENT WAY\", \"UNSHELTERED\", \"UNHOUSED\", \"UNKKNOWN\", \n",
    "                          \"UNKNWOWN\", \"UNKONW\", \"UNKOWN\", \"UNSTABLE HOUSING\", \"XNEEDX\", \"XNEEDSX\", \"HOMELEXX\", \"X NEED X\", \n",
    "                          \"TRANSET\", \"MISSING\", \"MAILING ADDRESS\", \"MAILING ONLY\", \"NOT AVAILABLE\", \"NOT PROVIDED\", \n",
    "                          \"THIS IS NOT A HOME ADDRESS\", \"MAIL RTND BAD ADDRESS\", \"MAILING ADDRESS ONLY\", \"NEED NEW ADDRESS\", \n",
    "                          \"FILLING OUT FORMS\", \"ADDRS VERF\", \"NO ACTUAL ADDRESS\", \"NEEDS ADDRESS\", \"DOES NOT HAVE AN ADDRESS\", \n",
    "                          \"REQUEST CALL\", \"UNABLE TO PROVIDE\", \"RETURN MAIL\", \"BAD ADDRESS\", \"UNABLE TO LOCATE\", \n",
    "                          \"NOT GIVEN\", \"NONE GIVEN\", \"NO KNOWN ADDRESS\"])\n",
    "peh_keywords = invalid_addr1 + \"|450 BAUCHET\"\n",
    "peh_keywords1 = ['NOT PROVIDED', 'UNSPECIFIED', '*NONE', 'REFUSED', '`', 'NULL', 'NONE', 'NA', 'N/A',  \n",
    "                 'ODR', 'SHELTER', 'IN TRANSIT', 'UNK']\n",
    "peh_keywords2 = peh_keywords1 + ['CA', 'NOT CALIFORNIA', 'LAC']\n",
    "\n",
    "# Continue defining the keyword lists\n",
    "invalid_addr15 = \"|UPDATE DEMO MAIL RTN|123 TEST|TEST PATIENT|TEST STREET|UPDATE DEMO|ROUTINE POSTPARTUM|\" + \\\n",
    "                \"123 MISSING|^HOMELES.*|^UNHOUSED.*|^UNSHELTER.*|^TRANSIENT.*|^UNK.*|^PRIV.*|^UNSPEC.*|^PT STATES.*|\"\n",
    "invalid_addr3 = peh_keywords1 + ['YES', '1234 ST', 'TBA', 'TBD', 'TEST 1', 'TEST', 'UNITED STATES', 'US', 'USA',\n",
    "                                 'MAIL ONLY', 'MAIL RETURNED', 'MAILING', 'ANTHEM BLUE CROSS', 'SANTA MONICA BEACH',\n",
    "                                 'SPRING', 'TEXT', 'NAME', '1 HOME', 'HOTEL', '1 FAKE', 'SPANISH', \n",
    "                                 'SPECIMEN NOT COLLECTED',  'UPDATE', '1 NEED', 'MAIN HOUSE', 'MANAGER', \n",
    "                                 'MANAGER OFFICE', 'MANAGER UNIT', 'XX', 'XX OTHER', 'PATIENT REFUSED', \n",
    "                                 'NOT PROVIDED', \"^REFUS.*\", \"^NO ADDRESS.*\", 'NOT AVAILABLE']\n",
    "invalid_addr4 = invalid_addr3 + ['CALIFORNIA', 'CA']\n",
    "invalid_addr5 = invalid_addr4 + ['LOS ANGELES', 'LA', '# LA', '#LA', 'N A', 'NA', '999 TRANSIENT WAY', \n",
    "                                 '999 TRANSIENT', '99 JAIL CASE', '123 UNK', '9999 TRANSIENT', '9999 TRANSIENT WAY', \n",
    "                                 '9999 TRANSIENT', 'SOUTHBAY ER', 'XXX HOMELESS XXX', 'POST OFFICE BOX', \n",
    "                                 'PTIENT STATES', 'SUNSET ED', 'VALLEY PALMS CARE CENTER', 'W LOS ANGELES ED', \n",
    "                                 'WLA ED', 'UNK']\n",
    "\n",
    "# Invalid apartment numbers\n",
    "invalid_apt1 = invalid_addr1 + \"|UNITED CARE FACILITES|HEALTH CARE|WE DO HAVE A NEW REGISTRATION|\" + \\\n",
    "               \"UNITED CEREBRAL PALSEY|UNITED STATES\"\n",
    "invalid_apt2 = invalid_addr4 + ['YES', '-', '1 LAB', 'APT SUITE FLOOR ETC.', 'NO APT']\n",
    "invalid_apt3 = invalid_addr5 + [\"UNITED CARE FACILITES\", \"HEALTH CARE\", \"WE DO HAVE A NEW REGISTRATION\", \n",
    "                                \"UNITED CEREBRAL PALSEY\", \"UNITED STATES\", \"BELLFLOWER CHRISTIAN\", \n",
    "                                \"GRAND PARK CONVALESCENT\", 'BRUIN PLAZA', 'YES', '-', '1 LAB', \n",
    "                                'APT SUITE FLOOR ETC', 'NO APT']\n",
    "\n",
    "# Key phrases for invalid apartment units\n",
    "invalid_apt_frag = [\"CONV\", \"HEALTH\", \"MEDICAL\", \"NURSING\", \"ACUTE\", \"CARE\", \"SOBER\", \"REHAB\", \"ASSISTED\",\n",
    "                    \"LIVING\", \"MANOR\", \"VILLA\", \"RETIREMENT\", \"BEH\", \"SENIOR\", \"SNF\", \"RESID\", \"SANIT\", \"CHURCH\",\n",
    "                    \"ACUTE\", \"HEALTHCARE\", \"WELLNESS\", \"CONGREGATE\", \"CONVALESCENT\", \"GLENDORA GRAND\", \"REHABILITATION\",\n",
    "                    # Other terms\n",
    "                    \"HOME\", \"HOUSE\", 'HEIGHT', 'COUNTRY', 'GARDEN', 'COTTAGE',  'ADDR', 'C/O', \n",
    "                    'POBOX', 'PLAZA', 'UNABLE', 'TRANSIENT', 'JAIL', 'PRISON', 'THE', 'SAME', 'VISTA', 'MAIL', 'PARK', \n",
    "                    'OFFICE', 'LAPD', 'LETTER', 'HOTEL', 'INN', 'MOTEL', 'COUNTY', 'UPPER', 'LOWER', 'REAR', 'DOWN', \n",
    "                    'UP', 'TEST', 'UNI', 'STADIUM']\n",
    "\n",
    "# Invalid cities\n",
    "invalid_city = ['NULL', 'NONE', 'NA', 'N/A', 'YES', 'REFUSED', '`', 'NOT PROVIDED', 'UNK', '', 'UNKKNOWN', \n",
    "                'UNKNWOWN', 'UNKONW', 'UNKOWN', 'UNSPECIFIED', 'UNITED STATES', 'US', 'CALIFORNIA', 'CA', ' ', '*NONE']\n",
    "\n",
    "# POBOX keywords\n",
    "pobox_keywords = \"POBOX|PO BOX|P0 BOX|POSTAL|PO BX|9O BOX|OK BOX|P 0  BOX|P BOX|PB BOX|PI BOX|PIC BOX|P.O. BOX|\" + \\\n",
    "                 \"P.O.BOX|PIO BOX|PITZER BOX|PO B0X|PO BAX|PO BOS|PO BOT|PO BOV|POX BOX|SHOW BOX|POP BOX|P O BOX|POX BOX\"\n",
    "\n",
    "# Unknown phone numbers\n",
    "unknown_numbers = [\"0000000000\", \"1111111111\", \"2222222222\", \"3333333333\", \"4444444444\", \"5555555555\", \n",
    "                   \"6666666666\", \"7777777777\", \"8888888888\", \"9999999999\", \"0000000001\"]\n",
    "\n",
    "# Unknown email keywords\n",
    "unknown_emails1 = \"GENERATED|NOEMAIL|NOMAIL|REFUSE|UNKNOWN|NO@NO|NA@NA|PATIENT|\" + \\\n",
    "                  \"DOES NOT|MISSING|NONAME|DECLINED|ASK FOR|NOT GIVEN\"\n",
    "unknown_emails2 = ['NAGMAIL.COM', 'N', 'DECLINED', 'NA', 'NO', 'TEST', 'NONE', 'GOBACKTOASK']\n",
    "\n",
    "# Unknown names\n",
    "unknown_names1 = \"NO FIRST NAME|NO INFO\"\n",
    "unknown_names2 = [\"TEST\", \"PATIENT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming invalid_addr1, invalid_addr2, ..., invalid_apt1, ..., etc. are lists\n",
    "# Convert any string components to lists\n",
    "invalid_addr1_list=invalid_addr1.split('|')\n",
    "invalid_addr15_list=invalid_addr15.split('|')\n",
    "pobox_keywords_list = pobox_keywords.split('|')\n",
    "invalid_apt1_list = invalid_apt1.split('|')\n",
    "unknown_emails1_list = unknown_emails1.split('|')\n",
    "unknown_names1_list = unknown_names1.split('|')\n",
    "\n",
    "# Combine all keywords into a single list\n",
    "#all_invalid_keywords = invalid_addr1_list + invalid_addr15_list +invalid_addr3 + invalid_addr4 +\\\n",
    "#invalid_addr5 + invalid_apt1_list + invalid_apt2 + invalid_apt3 + pobox_keywords_list + unknown_numbers +\\\n",
    "#unknown_emails1_list +  unknown_emails2 + unknown_names1_list + unknown_names2\n",
    "\n",
    "# Combine all keywords into a single list\n",
    "# Ensure all keywords are strings and in uppercase for case-insensitive comparison\n",
    "all_invalid_keywords = [str(keyword).upper() for keyword in ( invalid_addr1_list + invalid_addr15_list +invalid_addr3 + invalid_addr4 +\\\n",
    "invalid_addr5 + invalid_apt1_list + invalid_apt2 + invalid_apt3 + pobox_keywords_list + unknown_numbers +\\\n",
    "unknown_emails1_list +  unknown_emails2 + unknown_names1_list + unknown_names2)]\n",
    "\n",
    "def check_invalid_component(parsed_addr, invalid_keywords):\n",
    "    for component_type, component_value in parsed_addr.items():\n",
    "        # Skip certain components from direct keyword matching\n",
    "        if component_type in ['AddressNumber', 'AddressNumberPrefix', 'AddressNumberSuffix', 'StreetName', 'StreetNamePostType', \n",
    "                    'StreetNamePreDirectional','OccupancyType','OccupancyIdentifier','PlaceName','StreetNamePreType']:\n",
    "            continue\n",
    "\n",
    "        if any(keyword in component_value.upper() for keyword in invalid_keywords):\n",
    "            print(f\"Invalid component found: {component_type} -> {component_value}\")\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def clean_address(address, invalid_keywords):\n",
    "    try:\n",
    "        parsed_address, _ = usaddress.tag(address)\n",
    "        if check_invalid_component(parsed_address, invalid_keywords):\n",
    "            return \"\"  # Return empty string if invalid\n",
    "        return address  # Return original address if valid\n",
    "    except usaddress.RepeatedLabelError as e:\n",
    "        print(f\"Error parsing address '{address}': {e}\")\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we will do the same thing with the city, state and zipcodes i.e. compare them to the invalid keywords\n",
    "\n",
    "# Define invalid keyword lists for city, state, and zipcode\n",
    "invalid_city_keywords = invalid_addr4 # Add more as needed\n",
    "invalid_state_keywords = invalid_addr3  # Add more as needed\n",
    "invalid_zip_keywords = invalid_addr5  # Add more as needed\n",
    "\n",
    "def check_invalid_component(parsed_addr, city_keywords, state_keywords, zip_keywords):\n",
    "    is_invalid = False\n",
    "    for component_type, component_value in parsed_addr.items():\n",
    "        if component_type == 'PlaceName' and any(kw in component_value.upper() for kw in city_keywords):\n",
    "            is_invalid = True\n",
    "        elif component_type == 'StateName' and any(kw in component_value.upper() for kw in state_keywords):\n",
    "            is_invalid = True\n",
    "        elif component_type == 'ZipCode' and any(kw in component_value.upper() for kw in zip_keywords):  # Corrected key\n",
    "            is_invalid = True\n",
    "    return is_invalid\n",
    "\n",
    "def clean_location(city, state, zipcode, city_keywords, state_keywords, zip_keywords):\n",
    "    try:\n",
    "        pseudo_address = f\"{city}, {state} {zipcode}\"  # Corrected variable name\n",
    "        parsed_address, _ = usaddress.tag(pseudo_address)\n",
    "        if check_invalid_component(parsed_address, city_keywords, state_keywords, zip_keywords):\n",
    "            return \"\", \"\", \"\"  # Return empty strings if invalid\n",
    "        return city, state, zipcode  # Return original values if valid\n",
    "    except usaddress.RepeatedLabelError:\n",
    "        print(f\"Error parsing pseudo address '{city}, {state} {zipcode}'\")\n",
    "        return \"\", \"\", \"\"  # Handle parsing errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I need to also do the same thing for the apt field\n",
    "# Define your list of invalid keywords for apartment numbers\n",
    "invalid_apt_keywords = invalid_addr5  # Add your keywords\n",
    "\n",
    "def is_valid_apt(apt, invalid_keywords):\n",
    "    # Check if the apartment number is in the invalid keywords\n",
    "    if any(kw.lower() in apt.lower() for kw in invalid_keywords):\n",
    "        return \"\"\n",
    "    return apt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apt_keywords = ['Apt', 'Unit', 'Suite', 'Bldg', 'Room', 'Fl', '#']\n",
    "\n",
    "# Regular expression pattern for extracting apartment/unit numbers\n",
    "apt_pattern = r'\\b(?:' + '|'.join(apt_keywords) + r')\\s*\\S+'\n",
    "\n",
    "def extract_apt(addr):\n",
    "    match = re.search(apt_pattern, addr, re.IGNORECASE)\n",
    "    return match.group(0) if match else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_repeat_char(df, var, repeat_num=0):\n",
    "    # Create a regular expression for repeated characters\n",
    "    repeat_char_regex = r\"^(.)\\1*$\"\n",
    "\n",
    "    # Identify rows with invalid data\n",
    "    df['invalid'] = df[var].apply(lambda x: (bool(re.match(repeat_char_regex, x)) and len(x) > repeat_num) or x in [\"0\", \"00\"])\n",
    "\n",
    "    # Replace invalid data with an empty string\n",
    "    df[var + '_new'] = df.apply(lambda row: \"\" if row['invalid'] else row[var], axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_spec_char(df, var):\n",
    "    # Define a regex pattern that checks for the absence of alphanumeric characters\n",
    "    spec_char_regex = r\"^[^a-zA-Z\\d]+$\"\n",
    "\n",
    "    # Identify rows with only special characters and mark them as invalid\n",
    "    df['invalid'] = df[var].apply(lambda x: bool(re.match(spec_char_regex, x)) if pd.notna(x) else False)\n",
    "\n",
    "    # Replace invalid data with an empty string\n",
    "    df['new_' + var] = df.apply(lambda row: \"\" if row['invalid'] else row[var], axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_num_only(df, var):\n",
    "    # Remove all non-alphanumeric characters and check if the remaining string is numeric\n",
    "    df['invalid'] = df[var].apply(lambda x: x.isalnum() and x.isdigit() if pd.notna(x) else False)\n",
    "\n",
    "    # Replace invalid data with an empty string\n",
    "    df['new_' + var] = df.apply(lambda row: \"\" if row['invalid'] else row[var], axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_email(df, var):\n",
    "    # Define a regex pattern for email addresses\n",
    "    email_regex = r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\b\"\n",
    "\n",
    "    # Identify rows with email addresses and mark them as invalid\n",
    "    df['invalid'] = df[var].apply(lambda x: bool(re.search(email_regex, x)) if pd.notna(x) else False)\n",
    "\n",
    "    # Replace invalid data with an empty string\n",
    "    df['new_' + var] = df.apply(lambda row: \"\" if row['invalid'] else row[var], axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dates_only(df, var):\n",
    "    # Define regex patterns for date formats\n",
    "    date_patterns = [\n",
    "        r\"\\d{2}/\\d{2}/\\d{4}\",  # mm/dd/yyyy\n",
    "        r\"\\d{2}/\\d{2}/\\d{2}\",  # mm/dd/yy\n",
    "        r\"\\d{2}-\\d{2}-\\d{4}\",  # mm-dd-yyyy\n",
    "        r\"\\d{2}-\\d{2}-\\d{2}\"   # mm-dd-yy\n",
    "    ]\n",
    "\n",
    "    # Combine patterns into a single regex\n",
    "    combined_pattern = '|'.join(date_patterns)\n",
    "\n",
    "    # Identify rows with date-like strings\n",
    "    df['invalid'] = df[var].apply(lambda x: bool(re.search(combined_pattern, x)) if pd.notna(x) else False)\n",
    "\n",
    "    # Replace invalid data with an empty string\n",
    "    df['new_' + var] = df.apply(lambda row: \"\" if row['invalid'] else row[var], axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_two_word(df, var):\n",
    "    street_suffix = [\"RD\", \"ST\", \"ROAD\", \"STREET\", \"PL\", \"PLACE\", \"LN\", \"LANE\", \"UPDATE\", \"OTHER\"]\n",
    "    \n",
    "    def is_invalid(address):\n",
    "        if pd.isna(address):\n",
    "            return False\n",
    "        words = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", address.replace(\"  \", \" \")).split()\n",
    "        if len(words) != 2:\n",
    "            return False\n",
    "        return (words[1] in street_suffix and \n",
    "                bool(re.match(r\"^(.)\\1*$\", words[0])) and \n",
    "                len(words[0]) > 1) or (words[0].replace(\"0\", \"\") == \"\")\n",
    "\n",
    "    df['invalid'] = df[var].apply(is_invalid)\n",
    "\n",
    "    # Replace invalid data with an empty string\n",
    "    df['new_' + var] = df.apply(lambda row: \"\" if row['invalid'] else row[var], axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_parse(df, var):\n",
    "    # List of apartment keywords\n",
    "    apt_names_st = ['APT', 'APP', 'AP', 'APACE', 'APARTMENT', 'CONDO', 'NO', 'STE', 'SUITE', 'SPC', 'UNIT', \n",
    "                    'BUILD', 'BLDG', 'BUILDING', 'RM', 'ROOM']\n",
    "\n",
    "    # Create regex pattern for extracting unit\n",
    "    apt_pattern_out = r\"(?i)\\b(\" + \"|\".join(apt_names_st) + r\")\\s*\\#?\\s*[\\d\\w]+\"\n",
    "\n",
    "    # Function to extract unit\n",
    "    def extract_unit(address):\n",
    "        match = re.search(apt_pattern_out, address)\n",
    "        return match.group(0) if match else ''\n",
    "\n",
    "    # Function to remove unit\n",
    "    def remove_unit(address):\n",
    "        return re.sub(apt_pattern_out, '', address).strip()\n",
    "\n",
    "    # Apply the functions to create new columns\n",
    "    df['new_address'] = df[var].apply(remove_unit)\n",
    "    df['new_address_unit'] = df[var].apply(extract_unit)\n",
    "\n",
    "    return df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tomenv",
   "language": "python",
   "name": "tomenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
